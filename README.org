#+TITLE: Samples NASM x86 Assembly
#+DATE: <2025-04-11 Fri>
#+startup: show5levels

Code based on the lessons from the book [[https://a.co/d/hE556TU][Beginning x64 Assembly Programming]]
(repository [[https://github.com/Apress/beginning-x64-assembly-programming][link]]). The assembly used here is named [[https://en.wikipedia.org/wiki/Netwide_Assembler][NASM]] that stands for Netwide
Assembler. Also, to complement some gaps from the book explanation, I decided to
use ChatGPT.

Other interesting references are:

- [[https://www.intel.com/content/www/us/en/developer/articles/technical/intel-sdm.html][Intel manuals]]
- [[https://asmtutor.com/][asmtutor]]
- [[https://www.cs.virginia.edu/~evans/cs216/guides/x86.html][x86 Assembly Guide]]
- [[https://agner.org/optimize/][Agner's optimizations]]
- [[https://github.com/trevor-vincent/awesome-high-performance-computing][trevor-vincent/awesome-high-performance-computing]]

** Tools

Tools that you can use to debug and study the assembly code execution:

- SASM
- DDD
- GDB
- objdump
- [[https://godbolt.org/][godbolt compiler explorer (online)]]

** .data section

In NASM for x86 assembly, the directives like ~db~, ~dw~, ~dd~, ~dq~, etc., are
used to define data in memory. These *are not data types in the high-level
language sense* , but rather instructions to the assembler about how many bytes
to allocate and optionally what initial values to store there.

| Directive | Stands for        | Bytes allocated                       |
|-----------+-------------------+---------------------------------------|
| db        | Define byte       | 1 byte                                |
| dw        | Define word       | 2 bytes                               |
| dd        | Define Doubleword | 4 bytes                               |
| dq        | Define Quadword   | 8 bytes                               |
| dt        | Define Ten bytes  | 10 bytes (used for FPU 80-bit floats) |

Example:

#+BEGIN_SRC nasm
  section .data
          my_byte      db 0x41           ; 1 byte initialized to 0x41
          my_string    db 'Hello', 0     ; A null-terminated string
          my_word      dw 0x1234         ; 2 bytes initialized to 0x1234
          my_dword     dd 0x12345678     ; 4 bytes initialized to 0x12345678
          my_qword     dq 0x123456789ABCDEF0 ; 8 bytes
          my_tbyte     dt 0              ; 10 bytes initialized to 0
#+END_SRC

These directives are typically used in the ~.data~ or ~.bss~ sections of the
assembly program.

*** FPU 80-bit floats

We can find 80-bit floating-point numbers in old programs, where these numbers
have their own instructions, called FPU instructions. This functionality is a
legacy from the past and should not be used in new developments.

*** Constants

In NASM, the ~equ~ directive is used to define a constant - it's short for
"equate".

It doesn't allocate memory; instead, it assigns a name to a constant value that
will be substituted by the assembler wherever that name appears.

#+BEGIN_SRC nasm
  section .data
          BUFFER_SIZE equ 128 ; define a constant
#+END_SRC

This helps you avoid hardcoding numbers, making your code more readable and
easier to update.

** .bss section

In NASM, the ~.bss~ section is used to declare **uninitialized data** - i.e.,
memory that will be reserved but not initialized in the binary file. There we
can find directives for reserving some memory space, for example:

| Directive | Stands for          | Reserves                |
|-----------+---------------------+-------------------------|
| resb      | Reserve bytes       | 1 byte each             |
| resw      | Reserve words       | 2 bytes each            |
| resd      | Reserve Doublewords | 4 bytes each            |
| resq      | Reserve Quadwords   | 8 bytes each            |
| rest      | Reserve Ten bytes   | 10 bytes each (for FPU) |

Example:

#+BEGIN_SRC nasm
  section .bss
          buffer resq 4      ; reserves space for 4 quadwords = 4 * 8 = 32 bytes
#+END_SRC

+ WARNING :: Notice that we can't use the ~resq~ directive in the .data section.

** The stack

When your main program calls a function, it will push an 8-byte (64-bits) return
address on the stack. That 8-byte address is the address of the instruction to
be executed after the function ends.

Furthermore, the stack, which is a contiguous array of memory locations, can be
used as temporary storage to save generic values in registers and call them back
later or, more importantly, to transfer values to functions.

The stack segment starts in high memory, and when it grows, it grows in the
downward direction, like an icicle grows downward when it grows larger. Items
are places on the stack with the push instruction and removed from the stack
with the pop instruction.

*** The stack pointer

The stack pointer is a special register (called ~rsp~ in *x86_64*) that always
points to the current top of the stack.

*** The stack frame

A stack frame is the section of the stack used by one function call. It stores:

- The return address (from ~call~);
- The previous frame pointer (~rbp~);
- Local variables;
- Temporarily saved registers.

A stack frame is usually managed like this:

#+BEGIN_SRC nasm
  ; function prologue
  push rbp          ; Save caller's base pointer
  mov rbp, rsp      ; Set current frame pointer
  sub rsp, N        ; Reserve space for local variables

  ; ...

  ; function epilogue
  mov rsp, rbp      ; Restore stack pointer
  pop rbp           ; Restore caller's base pointer
  ret               ; Return to caller
#+END_SRC

Registers involved:

| Register | Role                                                  |
|----------+-------------------------------------------------------|
| ~rsp~    | Stack pointer (top of the stack)                      |
| ~rbp~    | Base pointer (start of the frame)                     |

*** Stack alignment

Stack alignment ensures that the stack pointer (~rsp~) is at a memory address
that's a multiple of a certain number of bytes - *typically 16 bytes on x86_64
systems*.

**** Why align the stack?

+ Performance :: Modern CPUs are optimized for aligned memory access.
+ Calling convention requirement :: The System V AMD64 ABI (used on Linux/macOS)
  requires ~rsp~ to be 16-byte aligned before any ~call~ instruction (used for
  calling external functions for example).
+ SIMD instructions :: Some instructions (e.g., those using ~xmm~ registers)
  require 16-byte alignment.
+ Debug tools :: Some debug tools demand the alignment of the stack to work
  properly.

** Functions

Assembly language has functions and procedures to help you give your code more
structure.

+ Function :: A function executes instructions and returns a value.
+ Procedure :: A procedure executes instructions and does not return a value.

*** External functions

In the source file where you plan to use the external function, you declare it
with the keyword ~extern~, and the assembler knows it does not have to look for
the source of the function. The assembler will assume that the function is
already assembled in an object file. The external function will be inserted by
the linker, provided it can find it in an object file.

And why we don't need to manually add the reference to the *printf* object file?

Well, ~gcc~ is smart enough to also check C libraries for functions that are
referenced in the source code. This means you should not use the names of C
functions for naming your own functions!

*** Macros

When you use the same set of instructions several times in a program, you can
create a function and call that function every time you need to execute the
instructions. However, there's a performance penalty with functions: every time
you call a function, the execution jumps to the function at some place in memory
and, when finished, jumps back to the calling program. Calling and returning
from a function takes time.

To avoid this performance issue, you can work with macros. [...] At assembly
time, everywhere in the code where you "call" the macro, NASM substitutes the
macro name with the instructions in the definition of the macro.

Macros are not a functionality in the Intel assembly language but a
functionality provided by NASM (or another version of assembler). Macros are
created using preprocessor directives, and NASM uses a macro processor to
convert macros to machine language and insert the machine languages at the
appropriate places in the code.

Macros could improve the execution speed of your code but also will increase the
size of the binary, because at assembly time the instructions in the macro will
be inserted every place that you use the macro.

Check the following projects for an initial understanding of using macros and
assembler preprocessor directives:

- [[file:012-macros/macro.asm][012-macros/macro.asm]]
- [[file:014-file-io/file.asm][014-file-io/file.asm]]
  
** How we know which registers to use for function arguments?

We use [[https://wiki.osdev.org/System_V_ABI][System V Application Binary Interface Calling Convention]] (for
Linux/macOS), which is the standard for passing arguments to functions in 64-bit
Linux programs.

Here's how it works for non-floating-point arguments, such as integers and
addresses:

| Argument # | Register | Notes                            |
|------------+----------+----------------------------------|
| 1st        | ~rdi~    |                                  |
| 2nd        | ~rsi~    |                                  |
| 3rd        | ~rdx~    |                                  |
| 4th        | ~rcx~    |                                  |
| 5th        | ~r8~     |                                  |
| 6th        | ~r9~     |                                  |
| 7th+       | Stack    | Pushed right-to-left (like in C) |

The return value (if any) is stored in ~rax~ register.

Floating-point arguments are passed via xmm registers as follows:

| Argument # | Register |
|------------+----------|
| 1st        | ~xmm0~   |
| 2nd        | ~xmm1~   |
| 3rd        | ~xmm2~   |
| 4th        | ~xmm3~   |
| 5th        | ~xmm4~   |
| 6th        | ~xmm5~   |
| 7th        | ~xmm6~   |
| 8th        | ~xmm7~   |
| 9th+       | Stack    |

A function returns a floating-point result in ~xmm0~ register.

Check the [[file:010-calling-convention/][010-calling-convention/function5.asm]] for an example.

Other than defining the calling convention, this interface specifies object file
formats, executable file formats, dynamic linking semantics, and much more for
systems that complies with the *X/Open Common Application Environment
Specification* and the *System V Interface Definition*. The *Executable and
Linkable Format* (~ELF~) is part of the ~System V ABI~.

For Microsoft we use the *Microsoft x64* calling convention.

*** Special case: variadic functions (like ~printf~)

+ Variadic functions :: Functions that accept a variable number of arguments,
  not a fixed number. For example: (C) ~printf(const char *format, ...)~

You must set ~rax~ to 0 before calling a variadic function like ~printf~ with no
floating-point arguments.

Otherwise, we set its value according to how many floating-point arguments are
in ~xmm~ registers.

** Processor's available functionalities

Sometimes it's necessary to find out the functionality available in a processor,
for example, to use an instruction that can deal with parallelization. One can
get this information using the ~cpuid~ command that checks the CPU
characteristics.

Check the [[file:018-cpuid/cpu.asm][018-cpuid/cpu.asm]] sample for a coding example.

** SIMD - Single Instruction, Multiple Data

*SIMD* refers to the functionality that allows you to execute one instruction on
multiple data "streams", which can potentially improve the performance of our
programs.

In essence, SIMD is a form of parallel computing; however, in some cases, the
execution on the different data streams can happen sequentially, depending on
the hardware functionality and the instruction to be executed.

SIMD is a term proposed by Michael J. Flynn, and to find more about the his
taxonomy, check the following references:

- IEEE Paper :: [[https://ieeexplore.ieee.org/document/5009071][Some Computer Organizations and Their Effectiveness]]
- Wikipedia  :: [[https://en.wikipedia.org/wiki/Flynn%27s_taxonomy][Flynn's taxonomy]]

Because of the potential for parallel computing, SIMD can be used to speed up
computations in a wide area of applications such as image processing, audio
processing, signal processing, vector and matrix manipulations, and so on.

*** SIMD implementations

The first implementation of SIMD was called MMX, which was superseded by
Streaming SIMD Extension (SSE). Later, SSE was extended by Advanced Vector
Extension (AVX).

*** Scalar data and packed data

A processor that supports SSE functionality has 16 additional 128-bit (16 bytes)
registers (~xmm0~ to ~xmm15~) and a control register ~mxcsr~. That's it, we can
use more advanced operations with ~xmm~ registers other than dealing only with
floating-point calculations.

The ~xmm~ registers can contain *scalar data* or *packed data*.

- Scalar data :: Just one value. When we put 3.141592654 in ~xmm0~, the ~xmm0~
  contains a scalar value.
- Packed data :: Multiple values, like an array.

Here are the possibilities for storing values in an ~xmm~ register:

- Two 64-bit double-precision floating-point numbers;
- Four 32-bit single-precision floating-point numbers
- Two 64-bit integers (quadwords)
- Four 32-bit integers (double words)
- Eight 16-bit short integers (words)
- Sixteen 8-bit bytes or characters

AVX registers are called ~ymm~ and they're double the size of ~xmm~
(256-bit). There is also AVX-512, which provides registers that have 512 bits
and are called ~zmm~ registers.

*** Unaligned and aligned data

Data in memory can be unaligned or aligned on certain addresses that are
multiples of 16, 32, and so on. Aligning data in memory can drastically improve
the performance of a program. Here is the reason why: aligned packed SSE
instructions want to fetch memory chunks of 16 bytes at the time. When data is
not aligned, the CPU has to do more than one fetch to get the needed 16-byte
data, and that slows down the execution.

When using SSE, alignment means that data in section ~.data~ and in section
~.bss~ should be aligned on a 16-byte border. In NASM you can use the assembly
directive ~align 16~ and ~alignb 16~ in front of the data to be aligned.

Check those samples to better understand how to properly align data:

- [[file:019-sse-alignment/sse_unaligned.asm][019-sse-alignment/sse_unaligned.asm]]
- [[file:019-sse-alignment/sse_aligned.asm][019-sse-alignment/sse_aligned.asm]]
  
*** .NET

.NET provides hardware support for SIMD using a set of SIMD-accelerated types
under the ~System.Numerics~ namespace: [[https://learn.microsoft.com/en-us/dotnet/standard/simd][Use SIMD-accelerated numeric types]].

The following repositories must be good resources for learning more about it:

- https://github.com/CBGonzalez/SIMDIntro
- https://github.com/CBGonzalez/SIMDPerformance
- https://github.com/CBGonzalez/Core3Intrinsics-Intro
- [[https://xoofx.github.io/blog/2023/07/09/10x-performance-with-simd-in-csharp-dotnet/][10x Performance with SIMD Vectorized Code in C#/.NET]]
